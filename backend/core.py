import io
import json
import requests
import ast
import os
import re
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Cm

def analyze_missing_fields(docx_bytes, user_info_text):
    """
    åˆ†ææ¨¡æ¿å’Œä¸ªäººä¿¡æ¯ï¼Œè¿”å›å¯èƒ½ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨

    Args:
        docx_bytes: Wordæ–‡æ¡£å­—èŠ‚æ•°æ®
        user_info_text: ç”¨æˆ·ä¿¡æ¯æ–‡æœ¬

    Returns:
        list: ç¼ºå¤±çš„å­—æ®µåç§°åˆ—è¡¨
    """
    from docx import Document

    doc = Document(io.BytesIO(docx_bytes))

    # 1. æ”¶é›†è¡¨æ ¼çš„è¡¨å¤´å’Œå ä½ç¬¦ä¿¡æ¯
    placeholder_info = {}  # {å ä½ç¬¦: è¡¨æ ¼ä½ç½®æè¿°}
    all_headers = []  # æ‰€æœ‰è¡¨å¤´æ–‡æœ¬

    for t_idx, table in enumerate(doc.tables):
        if not table.rows:
            continue

        # è·å–è¡¨å¤´è¡Œ
        header_row = table.rows[0]
        headers = []
        for c_idx, cell in enumerate(header_row.cells):
            headers.append(cell.text.strip())

        # æ”¶é›†è¡¨å¤´ä¿¡æ¯
        for h_idx, header in enumerate(headers):
            if header and header not in all_headers:
                all_headers.append(header)

        # æ ‡è®°ç©ºå•å…ƒæ ¼å¹¶è®°å½•ä½ç½®
        max_cols = max(len(row.cells) for row in table.rows)
        counter = 1

        for r_idx, row in enumerate(table.rows):
            for c_idx in range(max_cols):
                if c_idx >= len(row.cells):
                    continue

                cell = row.cells[c_idx]
                text = cell.text.strip()

                if not text:
                    # ä¸ºç©ºå•å…ƒæ ¼åˆ›å»ºå ä½ç¬¦
                    tag = f"{{{counter}}}"
                    # å°è¯•æ‰¾åˆ°è¿™ä¸ªå ä½ç¬¦å¯¹åº”çš„è¡¨å¤´
                    header = headers[c_idx] if c_idx < len(headers) else ""
                    placeholder_info[tag] = {
                        "header": header,
                        "table_index": t_idx + 1,
                        "row_index": r_idx + 1,
                        "col_index": c_idx + 1
                    }
                    counter += 1

    if not placeholder_info:
        return []

    # 2. è°ƒç”¨ AI åˆ†æç¼ºå¤±çš„å­—æ®µ
    # å°†è¡¨æ ¼ä¿¡æ¯å’Œç”¨æˆ·ä¿¡æ¯ä¸€èµ·å‘ç»™ AIï¼Œè®©å®ƒæ¨æ–­éœ€è¦å“ªäº›å­—æ®µ
    headers_text = "\n".join([f"- {h}" for h in all_headers if h])
    placeholders_text = "\n".join([f"- {k}: è¡¨å¤´={v['header'] if v['header'] else 'æ— '}" for k, v in placeholder_info.items()])

    url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
    api_key = os.environ.get("ARK_API_KEY") or "5410d463-1115-4320-9279-a5441ce30694"
    model_endpoint = os.environ.get("MODEL_ENDPOINT") or "doubao-seed-1-6-251015"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¡¨å•å­—æ®µåˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹æ¨¡æ¿è¡¨æ ¼å’Œä¸ªäººä¿¡æ¯ï¼Œæ‰¾å‡ºè¡¨æ ¼ä¸­å¯èƒ½éœ€è¦ä½†ä¸ªäººä¿¡æ¯ä¸­ç¼ºå¤±çš„å­—æ®µã€‚

**ä»»åŠ¡ï¼š**
1. åˆ†æè¡¨æ ¼çš„è¡¨å¤´å’Œå ä½ç¬¦ï¼Œæ¨æ–­æ¯ä¸ªå ä½ç¬¦éœ€è¦å¡«å†™ä»€ä¹ˆç±»å‹çš„ä¿¡æ¯
2. å¯¹æ¯”ä¸ªäººä¿¡æ¯ï¼Œåˆ¤æ–­å“ªäº›é‡è¦å­—æ®µå¯èƒ½ç¼ºå¤±
3. è¿”å›ç¼ºå¤±çš„å…³é”®å­—æ®µåˆ—è¡¨ï¼ˆæœ€å¤šè¿”å› 5 ä¸ªæœ€é‡è¦çš„ï¼‰

**æ¨¡æ¿è¡¨æ ¼çš„è¡¨å¤´ï¼š**
{headers_text}

**æ¨¡æ¿éœ€è¦çš„å­—æ®µï¼ˆå ä½ç¬¦å¯¹åº”å…³ç³»ï¼‰ï¼š**
{placeholders_text}

**ç”¨æˆ·å·²å¡«å†™çš„ä¿¡æ¯ï¼š**
{user_info_text}

**è¿”å›æ ¼å¼ï¼š**
è¯·ä»¥çº¯ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œç¤ºä¾‹ï¼š
["èº«é«˜(cm)", "æ°‘æ—", "å­¦å†"]

åªè¿”å›å­—æ®µåç§°ï¼Œç”¨ä¸­æ–‡é¡¿å·ï¼ˆã€ï¼‰åˆ†éš”ã€‚æœ€å¤šè¿”å› 5 ä¸ªæœ€é‡è¦çš„ç¼ºå¤±å­—æ®µã€‚"""

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {
        "model": model_endpoint,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,  # è¾ƒä½æ¸©åº¦ä½¿ç»“æœæ›´ç¨³å®š
        "top_p": 0.7,
        "max_tokens": 500
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code != 200:
            return []

        res_json = response.json()
        content = res_json['choices'][0]['message']['content']

        # æ¸…ç† Markdown ä»£ç å—æ ‡è®°
        content = content.replace("```json", "").replace("```", "").strip()

        # è§£æ JSON æ•°ç»„
        try:
            missing_fields = json.loads(content)
            if isinstance(missing_fields, list):
                return missing_fields[:5]  # æœ€å¤šè¿”å› 5 ä¸ª
            return []
        except json.JSONDecodeError:
            # å°è¯•æå–æ•°ç»„æ ¼å¼
            import re
            matches = re.findall(r'"([^"]+)"', content)
            if matches:
                return matches[:5]
            return []
    except Exception as e:
        print(f"âŒ åˆ†æç¼ºå¤±å­—æ®µå¤±è´¥: {e}")
        return []


def get_doubao_response(user_info, markdown_context):
    """
    å‚è€ƒ smart.py çš„æç¤ºè¯æ€è·¯ï¼Œä½¿ç”¨ Markdown è¡¨æ ¼ä½œä¸ºä¸Šä¸‹æ–‡
    """
    if isinstance(user_info, bytes):
        user_info = user_info.decode('utf-8')

    url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
    api_key = os.environ.get("ARK_API_KEY") or "5410d463-1115-4320-9279-a5441ce30694"
    model_endpoint = os.environ.get("MODEL_ENDPOINT") or "doubao-seed-1-6-251015"

    # å‚è€ƒ smart.py çš„æç¤ºè¯æ„å»ºæ–¹å¼
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å ä½ç¬¦æ›¿æ¢åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹ Markdown è¡¨æ ¼å’Œä¸ªäººä¿¡æ¯ï¼Œæ¨æ–­æ¯ä¸ªå ä½ç¬¦åº”è¯¥æ›¿æ¢æˆä»€ä¹ˆå†…å®¹ã€‚

**ä»»åŠ¡è¦æ±‚ï¼š**
1. ä»”ç»†åˆ†æè¡¨æ ¼ä¸­çš„å ä½ç¬¦æ ¼å¼ï¼ˆå¦‚ {{1}}ã€{{2}} ç­‰ï¼‰ã€‚
2. æ ¹æ®ã€ä¸ªäººä¿¡æ¯ã€‘æ¨ç†æ¯ä¸ªå ä½ç¬¦åº”è¯¥å¡«å…¥çš„å†…å®¹ï¼Œå…è®¸åˆç†æ¨ç†å’Œæ¨æ–­ã€‚
3. å¦‚æœæ— æ³•ç¡®å®šæŸä¸ªå ä½ç¬¦çš„å†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
4. è¿”å›æ ¼å¼å¿…é¡»æ˜¯çº¯ JSONï¼Œæ ¼å¼ä¸ºï¼š{{"{{1}}": "å†…å®¹", "{{2}}": "å†…å®¹"}}ã€‚
5. æ–‡å­—è¿‡é•¿è¯·æ³¨æ„æ¢è¡Œæ¥è®©æ’ç‰ˆæ›´ç¾è§‚ã€‚

**ä¸ªäººä¿¡æ¯ï¼š**
{user_info}

**Markdownè¡¨æ ¼ä¸Šä¸‹æ–‡ï¼š**
{markdown_context}

**æ³¨æ„ï¼š**
- åªè¿”å›éœ€è¦æ›¿æ¢çš„å ä½ç¬¦æ˜ å°„ã€‚
- ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ï¼Œä¸è¦åŒ…å«é¢å¤–çš„è§£é‡Šæ€§æ–‡å­—ã€‚"""

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {
        "model": model_endpoint, 
        "messages": [{"role": "user", "content": prompt}], 
        "temperature": 1, 
        "top_p": 0.7,
        "thinking": {"type": "disabled"}
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code != 200:
            return {}

        res_json = response.json()
        content = res_json['choices'][0]['message']['content']

        # æ¸…ç† Markdown ä»£ç å—æ ‡è®° (å‚è€ƒ smart.py çš„è§£æé€»è¾‘)
        content = content.replace("```json", "").replace("```", "").strip()

        # æ›´é²æ£’çš„ JSON æå–é€»è¾‘
        try:
            fill_data = json.loads(content)
        except json.JSONDecodeError:
            try:
                # å°è¯•åŒ¹é…ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                match = re.search(r'\{.*\}', content, re.DOTALL)
                if match:
                    extracted_json = match.group(0)
                    print(f"ğŸ“ æå–åˆ° JSON: {extracted_json[:100]}...")
                    fill_data = json.loads(extracted_json)
                else:
                    print("âš ï¸ æœªæ‰¾åˆ° JSON æ ¼å¼å†…å®¹")
                    fill_data = {}
            except (json.JSONDecodeError, AttributeError) as e:
                print(f"âŒ JSON è§£æå¤±è´¥: {e}")
                try:
                    fill_data = ast.literal_eval(content)
                except:
                    print("âŒ æ‰€æœ‰ JSON è§£ææ–¹æ³•éƒ½å¤±è´¥")
                    fill_data = {}

        # æ‰“å° fill_data ä¾› server_with_auth.py è®°å½•
        print(f"ğŸ“‹ AI ç”Ÿæˆçš„å¡«å……æ•°æ®: {fill_data}")
        return fill_data
    except Exception as e:
        print(f"âŒ Error during AI inference: {e}")
        return {}

def fill_form(docx_bytes, user_info_text, photo_bytes, return_fill_data=False):
    """
    å¡«å……è¡¨å•

    Args:
        docx_bytes: Wordæ–‡æ¡£å­—èŠ‚æ•°æ®
        user_info_text: ç”¨æˆ·ä¿¡æ¯æ–‡æœ¬
        photo_bytes: ç…§ç‰‡å­—èŠ‚æ•°æ®
        return_fill_data: æ˜¯å¦è¿”å›å¡«å……æ•°æ®ï¼ˆç”¨äºå‡å°‘é‡å¤æ¨ç†ï¼‰

    Returns:
        å¦‚æœ return_fill_data=Trueï¼Œè¿”å› (output_bytes, fill_data, missing_fields)
        å…¶ä¸­ missing_fields æ˜¯ç¼ºå¤±å­—æ®µçš„è¡¨å¤´/ä½ç½®ä¿¡æ¯åˆ—è¡¨
        å¦åˆ™è¿”å› output_bytes
    """
    doc = Document(io.BytesIO(docx_bytes))

    # 1. å¤„ç†ç…§ç‰‡å ä½ç¬¦
    photo_coords = []
    for t_idx, table in enumerate(doc.tables):
        for r_idx, row in enumerate(table.rows):
            for c_idx, cell in enumerate(row.cells):
                text_lower = cell.text.lower()
                if any(k in text_lower for k in ["ç…§ç‰‡", "ç›¸ç‰‡", "è¯ä»¶ç…§"]):
                    photo_coords.append((t_idx, r_idx, c_idx))

    if photo_coords and photo_bytes:
        for (t_idx, r_idx, c_idx) in photo_coords:
            cell = doc.tables[t_idx].rows[r_idx].cells[c_idx]
            cell.text = ""
            p = cell.paragraphs[0]
            p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = p.add_run()
            run.add_picture(io.BytesIO(photo_bytes), width=Cm(3.5))

    # 2. æ ‡è®°ç©ºå•å…ƒæ ¼å¹¶æ„å»º Markdown ä¸Šä¸‹æ–‡ (é›†æˆ smart.py æ ¸å¿ƒæ€è·¯)
    placeholder_map = {}
    placeholder_info = {}  # å­˜å‚¨å ä½ç¬¦å¯¹åº”çš„è¡¨å¤´ä¿¡æ¯
    counter = 1
    markdown_lines = []

    for t_idx, table in enumerate(doc.tables):
        markdown_lines.append(f"\n### è¡¨æ ¼ {t_idx + 1}\n")

        # é¢„è®¡ç®—å½“å‰è¡¨æ ¼çš„æœ€å¤§åˆ—æ•°
        max_cols = max(len(row.cells) for row in table.rows) if table.rows else 0

        for r_idx, row in enumerate(table.rows):
            row_cells_content = []
            for c_idx in range(max_cols):
                # è¶Šç•Œå¤„ç†
                if c_idx >= len(row.cells):
                    row_cells_content.append("")
                    continue

                cell = row.cells[c_idx]

                # è·³è¿‡å·²æ ‡è®°ä¸ºç…§ç‰‡çš„å•å…ƒæ ¼
                if (t_idx, r_idx, c_idx) in photo_coords:
                    row_cells_content.append("[ç…§ç‰‡]")
                    continue

                text = cell.text.strip()
                if not text:
                    # ä¸ºç©ºå•å…ƒæ ¼åˆ›å»ºå ä½ç¬¦
                    tag = f"{{{counter}}}"
                    cell.text = tag
                    placeholder_map[tag] = cell
                    # è·å–è¡¨å¤´ä¿¡æ¯
                    header = ""
                    if r_idx > 0 and c_idx < len(table.rows[0].cells):
                        header_cell = table.rows[0].cells[c_idx]
                        header = header_cell.text.strip()
                    # ä¿å­˜å ä½ç¬¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¡¨å¤´å’Œä½ç½®
                    placeholder_info[tag] = {
                        "header": header,
                        "table_index": t_idx + 1,
                        "row_index": r_idx + 1,
                        "col_index": c_idx + 1
                    }
                    row_cells_content.append(tag)
                    counter += 1
                else:
                    row_cells_content.append(text)
            
            # ç”Ÿæˆ Markdown è¡Œ
            markdown_lines.append("| " + " | ".join(row_cells_content) + " |")
            if r_idx == 0: # æ·»åŠ åˆ†å‰²çº¿
                markdown_lines.append("| " + " | ".join(["---"] * max_cols) + " |")

    if not placeholder_map:
        out = io.BytesIO()
        doc.save(out)
        output_bytes = out.getvalue()
        if return_fill_data:
            return output_bytes, {}
        return output_bytes

    # 3. è°ƒç”¨ AI è¿›è¡Œæ¨ç†
    fill_data = get_doubao_response(user_info_text, "\n".join(markdown_lines))

    # 4. æ”¶é›†æœªå¡«å……çš„å­—æ®µä¿¡æ¯
    missing_fields = []  # å­˜å‚¨æœªå¡«å……çš„å­—æ®µï¼ˆå€¼ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼‰
    placeholder_needs_ai_inference = {}  # å­˜å‚¨éœ€è¦ AI æ¨æ–­å­—æ®µåç§°çš„å ä½ç¬¦

    # 4. å¡«å……æ•°æ®
    if fill_data:
        for key, value in fill_data.items():
            # å…¼å®¹ AI è¿”å› "1" è€Œä¸æ˜¯ "{1}" çš„æƒ…å†µ
            target_key = key if key.startswith("{") else f"{{{key}}}"
            if target_key in placeholder_map:
                cell = placeholder_map[target_key]
                cell.text = str(value)
                for p in cell.paragraphs:
                    p.alignment = WD_ALIGN_PARAGRAPH.LEFT

                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼
                if not str(value).strip():
                    # ä½¿ç”¨ target_key è¿›è¡Œ lookupï¼Œå› ä¸º placeholder_info çš„ key æ ¼å¼æ˜¯ {1}
                    header_info = placeholder_info.get(target_key, {})
                    header = header_info.get('header', '')
                    if header:
                        # æœ‰è¡¨å¤´ï¼Œç›´æ¥ä½¿ç”¨è¡¨å¤´ä½œä¸ºå­—æ®µå
                        missing_fields.append(header)
                    else:
                        # æ²¡æœ‰è¡¨å¤´ï¼Œä» placeholder_info è·å–ä½ç½®ä¿¡æ¯
                        if target_key in placeholder_info:
                            pos_info = placeholder_info[target_key]
                            placeholder_needs_ai_inference[target_key] = {
                                "table_index": pos_info.get("table_index", 0),
                                "row_index": pos_info.get("row_index", 0),
                                "col_index": pos_info.get("col_index", 0)
                            }
                    print(f"âš ï¸ è¯†åˆ«åˆ°ç¼ºå¤±å­—æ®µ: {header if header else target_key} (å ä½ç¬¦: {target_key})")

    # 5. å¦‚æœæœ‰æ— è¡¨å¤´çš„ç¼ºå¤±å­—æ®µï¼Œç”¨ AI æ¨æ–­å­—æ®µåç§°
    if placeholder_needs_ai_inference:
        inferred_fields = infer_field_names_with_ai(
            placeholder_needs_ai_inference,
            "\n".join(markdown_lines),
            user_info_text
        )
        missing_fields.extend(inferred_fields)

    print(f"ğŸ“‹ ç¼ºå¤±å­—æ®µåˆ—è¡¨: {missing_fields}")

    out = io.BytesIO()
    doc.save(out)
    output_bytes = out.getvalue()

    if return_fill_data:
        return output_bytes, fill_data, missing_fields
    return output_bytes


def infer_field_names_with_ai(placeholder_info_map, markdown_context, user_info_text):
    """
    ä½¿ç”¨ AI æ¨æ–­ç¼ºå¤±å­—æ®µçš„åç§°ï¼ˆå½“è¡¨å¤´ä¸ºç©ºæ—¶ï¼‰

    Args:
        placeholder_info_map: å ä½ç¬¦ä¿¡æ¯å­—å…¸ {å ä½ç¬¦: {table_index, row_index, col_index}}
        markdown_context: Markdown è¡¨æ ¼ä¸Šä¸‹æ–‡
        user_info_text: ç”¨æˆ·å·²å¡«å†™çš„ä¿¡æ¯

    Returns:
        list: æ¨æ–­å‡ºçš„å­—æ®µåç§°åˆ—è¡¨
    """
    if not placeholder_info_map:
        return []

    url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
    api_key = os.environ.get("ARK_API_KEY") or "5410d463-1115-4320-9279-a5441ce30694"
    model_endpoint = os.environ.get("MODEL_ENDPOINT") or "doubao-seed-1-6-251015"

    # æ„å»ºå ä½ç¬¦ä¿¡æ¯
    placeholders_text = "\n".join([
        f"- {k}: è¡¨æ ¼{v['table_index']}ç¬¬{v['row_index']}è¡Œç¬¬{v['col_index']}åˆ—"
        for k, v in placeholder_info_map.items()
    ])

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¡¨å•å­—æ®µåˆ†æåŠ©æ‰‹ã€‚è¡¨æ ¼ä¸­æœ‰ä¸€äº›ç©ºå•å…ƒæ ¼æ²¡æœ‰è¡¨å¤´ï¼Œéœ€è¦ä½ æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­è¿™äº›å•å…ƒæ ¼åº”è¯¥å¡«å†™ä»€ä¹ˆç±»å‹çš„å­—æ®µã€‚

**ä»»åŠ¡ï¼š**
åˆ†æè¡¨æ ¼ç»“æ„å’Œç”¨æˆ·ä¿¡æ¯ï¼Œæ¨æ–­æ¯ä¸ªç©ºå•å…ƒæ ¼åº”è¯¥å¡«å†™ä»€ä¹ˆç±»å‹çš„å­—æ®µåç§°ï¼ˆå¦‚"èº«é«˜"ã€"ä½“é‡"ã€"æ¯•ä¸šé™¢æ ¡"ç­‰ï¼‰ã€‚

**è¡¨æ ¼ä¸Šä¸‹æ–‡ï¼š**
{markdown_context}

**éœ€è¦æ¨æ–­çš„å ä½ç¬¦ä½ç½®ï¼š**
{placeholders_text}

**ç”¨æˆ·å·²å¡«å†™çš„ä¿¡æ¯ï¼š**
{user_info_text}

**è¿”å›æ ¼å¼ï¼š**
è¯·ä»¥çº¯ JSON æ•°ç»„æ ¼å¼è¿”å›å­—æ®µåç§°ï¼Œé¡ºåºä¸å ä½ç¬¦é¡ºåºä¸€è‡´ï¼Œç¤ºä¾‹ï¼š
["èº«é«˜(cm)", "ä½“é‡(kg)", "æ¯•ä¸šé™¢æ ¡"]

åªè¿”å›å­—æ®µåç§°ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚å¦‚æœæ²¡æœ‰è¶³å¤Ÿä¿¡æ¯æ¨æ–­ï¼Œå¯ä»¥ä½¿ç”¨é€šç”¨æè¿°å¦‚"å­—æ®µ"ã€"ä¿¡æ¯"ç­‰ã€‚"""

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {
        "model": model_endpoint,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,
        "top_p": 0.7,
        "max_tokens": 500
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code != 200:
            # å¦‚æœ AI è°ƒç”¨å¤±è´¥ï¼Œè¿”å›å ä½ç¬¦ä½œä¸ºé»˜è®¤
            return list(placeholder_info_map.keys())

        res_json = response.json()
        content = res_json['choices'][0]['message']['content']

        # æ¸…ç† Markdown ä»£ç å—æ ‡è®°
        content = content.replace("```json", "").replace("```", "").strip()

        # è§£æ JSON æ•°ç»„
        try:
            inferred_fields = json.loads(content)
            if isinstance(inferred_fields, list):
                # ç¡®ä¿è¿”å›æ•°é‡ä¸å ä½ç¬¦æ•°é‡ä¸€è‡´
                if len(inferred_fields) == len(placeholder_info_map):
                    return inferred_fields
                else:
                    # æ•°é‡ä¸åŒ¹é…æ—¶ï¼Œè¡¥å……æˆ–æˆªæ–­
                    placeholders = list(placeholder_info_map.keys())
                    if len(inferred_fields) < len(placeholders):
                        return inferred_fields + placeholders[len(inferred_fields):]
                    else:
                        return inferred_fields[:len(placeholders)]
            return list(placeholder_info_map.keys())
        except json.JSONDecodeError:
            # å°è¯•æå–æ•°ç»„æ ¼å¼
            matches = re.findall(r'"([^"]+)"', content)
            if matches:
                return matches
            return list(placeholder_info_map.keys())
    except Exception as e:
        print(f"âŒ AI æ¨æ–­å­—æ®µåç§°å¤±è´¥: {e}")
        return list(placeholder_info_map.keys())